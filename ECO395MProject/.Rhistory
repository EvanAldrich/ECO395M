vgchart = read.csv("vgchartz.csv")
library(dplyr)
vgchart = read.csv("vgchartz.csv")
vgchartfilt = vgchart %>% filter(!is.na(total_sales) & total_sales != "")
vgchartfilt
library(dplyr)
vgchart = read.csv("vgchartz.csv")
vgchartfilt = vgchart %>% filter(!is.na(total_sales) & total_sales != "")
vgchartfilt
write.csv(vgchartfilt, "filt.csv")
library(dplyr)
vgchart = read.csv("vgchartz.csv")
vgchartfilt = vgchart %>% filter(!is.na(total_sales) & total_sales != "") %>% filter(!is.na(critic_score) & critic_score != "")
vgchartfilt
write.csv(vgchartfilt, "filt.csv")
library(dplyr)
vgchart = read.csv("vgchartz.csv")
vgchartfilt = vgchart %>% filter(!is.na(total_sales) & total_sales != "") %>% filter(!is.na(critic_score) & critic_score != "")
vgchartfilt
write.csv(vgchartfilt, "filt.csv")
data1 = read.csv("video_games.csv")
data2 = read.csv("2013_Video_Games_Dataset")
merged_data = merge(data1, data2, by = "Title")
write.csv(merged_data, "big_vg.csv")
data1 = read.csv("video_games.csv")
data2 = read.csv("2013_Video_Games_Dataset.csv")
merged_data = merge(data1, data2, by = "Title")
write.csv(merged_data, "big_vg.csv")
data1 = read.csv("video_games.csv")
data2 = read.csv("2013_Video_Games_Dataset.csv")
merged_data = merge(data1, data2, by = c("Title", "Console"))
write.csv(merged_data, "big_vg.csv")
capmetro = read.csv('capmetro.csv')
summary(capmetro)
capmetro = read.csv('capmetro.csv')
summary(capmetro)
capmetro = read.csv('capmetro.csv')
summary(capmetro)
library(tidyverse)
library(lubridate)
library(randomForest)
library(gbm)
library(pdp)
library(modelr)
library(rsample)
capmetro = read.csv('capmetro.csv')
summary(capmetro)
capmetro = read.csv("capmetro.csv")
summary(capmetro)
capmetro = read.csv("capmetro.csv")
summary(capmetro)
capmetro$zone = factor(capmetro$zone)
capmetro$day = factor(capmetro$day, levels=c('Monday','Tuesday', "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
capmetro = mutate(capmetro, hour = hour(timestamp),
min_of_day = 60*hour(timestamp) + minute(timestamp))
capmetro = mutate(capmetro, precipYes = ifelse(precipIntensity>0, 1, 0),
inSemester = ifelse(date(timestamp) %within%
interval(ymd("2018-08-29"), ymd("2018-12-07")), 1, 0))
ggplot(data=capmetro) +
geom_boxplot(mapping=aes(x=factor(hour), y=boarding))
hour_summ = capmetro %>%
group_by(hour, zone, day, inSemester) %>%
summarize(boarding_mean = mean(boarding))
ggplot(hour_summ) +
geom_col(aes(x=hour, y=boarding_mean)) +
facet_grid(day~zone)
ggplot(filter(hour_summ, zone==362)) +
geom_col(aes(x=hour, y=boarding_mean)) +
facet_grid(day~inSemester)
capmetro362 = filter(capmetro, zone==362)
capmetro362_split = initial_split(capmetro362)
capmetro362 = filter(capmetro, zone==362)
capmetro362_split = initial_split(capmetro362)
# training and testing sets
n = nrow(capmetro362)
capmetro362_train = training(capmetro362_split)
capmetro362_test = testing(capmetro362_split)
forest1 = randomForest(boarding ~ day + temperature + min_of_day + precipYes + inSemester,
data=capmetro362_train)
yhat_test = predict(forest1, capmetro362_test)
plot(yhat_test, capmetro362_test$boarding)
# RMSE
rmse(forest1, capmetro362_test)
# performance as a function of iteration number
plot(forest1)
# a variable importance plot: how much SSE decreases from including each var
varImpPlot(forest1)
boost1 = gbm(boarding ~ day + temperature + min_of_day + precipYes + inSemester,
data = capmetro362_train,
interaction.depth=4, n.trees=500, shrinkage=.05)
# Look at error curve -- stops decreasing much after ~300
gbm.perf(boost1)
yhat_test_gbm = predict(boost1, capmetro362_test, n.trees=350)
# RMSE
rmse(boost1, capmetro362_test)
# What if we assume a Poisson error model?
boost2 = gbm(boarding ~ day + temperature + min_of_day + precipYes + inSemester,
data = capmetro362_train, distribution='poisson',
interaction.depth=4, n.trees=350, shrinkage=.05)
n = nrow(capmetro362)
n
